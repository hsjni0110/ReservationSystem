# 개요
현재 pay() 메서드는 하나의 트랜잭션 내에서 여러 도메인 로직을 처리합니다. 이로 인해 서비스의 응집도와 결합도가 높아지고, 시스템의 확장성, 유연성, 장애 대응 능력에 한계가 생깁니다

본 보고서에서는 pay() 메서드의 책임 분리 문제와 그에 따른 구조적 문제점을 분석하고, 이를 개선하기 위한 설계 방향을 제안합니다.

# 현재 pay()의 메서드의 책임과 단점

```java
@Transactional  
public PaymentResponse pay( Long userId, Long reservationId ) {  
    User user = userRepository.getByIdOrThrow( userId );  
    Reservation reservation = reservationRepository.getByIdOrThrow( reservationId );  
    validate( user, reservation );  
    Payment payment = paymentManager.executePayment( user, reservation );  
    reservation.successPayment();  
    pointService.earnPoints( userId, payment.getTotalPrice(), UUID.randomUUID().toString() );  
    return new PaymentResponse( payment.getPaymentId(), payment.getTotalPrice().getAmount(), payment.getPaymentStatus(), payment.getCreatedAt() );  
}
```

## 기능 별 책임 분석

|**순번**|**기능**|**설명**|**해당 도메인**|
|---|---|---|---|
|1|User, Reservation 조회|엔티티 조회 및 null 방지|User, Reservation|
|2|유효성 검증|예약 상태 확인, 이중 결제 방지|Reservation|
|3|결제 금액 계산|결제 대상의 금액 결정|Reservation|
|4|계좌 차감|유저의 결제 수단에서 금액 차감|Account|
|5|Payment 생성|결제 도메인의 핵심 책임|Payment|
|6|Reservation 상태 변경|결제 완료 → 예약 확정 등 상태 전이|Reservation|
|7|포인트 적립|결제 금액에 따른 포인트 적립|Point


## 현재 구조의 문제점
### 1. 긴 트랜잭션으로 인한 성능 저하

현재 pay() 메서드는 하나의 트랜잭션 안에서 다음과 같은 **여러 도메인의 조회 및 갱신 로직**을 함께 처리합니다. 실제 실행 시간 로그를 보면 각 동작은 개별적으로는 빠르지만, **전체 트랜잭션 시간은 누적**되고 있으며, **서비스가 확장될수록 점점 더 느려질 위험**이 있습니다.

> User 조회 + Reservation 조회 : 3msec 소요

![Image](https://github.com/user-attachments/assets/88bf9887-d494-45b0-ba80-c62e0a907a6e)

![Image](https://github.com/user-attachments/assets/5b51167a-c979-4dd4-9cd4-e5c75b4ae4fa)

> Payment 상태 검증을 위한 조회 : 2msec 소요

![Image](https://github.com/user-attachments/assets/f1ca2384-f470-406d-8986-4b1c92ab6824)

> User의 Account 조회([[낙관적 락과 비관적 락|낙관적 락]] 적용) : 2msec 소요

![Image](https://github.com/user-attachments/assets/69ce2b44-b03e-4d05-b4e8-ecb9f91eed50)

> 예약 시의 좌석 조회 : 1 msec 소요

![Image](https://github.com/user-attachments/assets/94e4aff7-4f21-4cdb-bb8e-c0382d9aca74)

> 결제 정보 생성(Insert) : 2 msec 소요

![Image](https://github.com/user-attachments/assets/52a33a7e-c681-4946-88f5-b373fcb86bea)

> 포인트 적립 시, 중복 적립 여부 검증 : 1 msec 소요

![Image](https://github.com/user-attachments/assets/ab4e8395-8bd6-4572-b490-4e25dbcb61e9)

> 유저의 포인트 정보 조회 : 1 msec 소요

![Image](https://github.com/user-attachments/assets/b4f57533-83d4-4a38-857d-afb611de088a)

> 포인트 적립(Insert) : 1 msec 소요

![Image](https://github.com/user-attachments/assets/6303979c-a7d2-4aa5-b767-97d72d578d1a)

> 포인트 이력 삽입(Insert) : 1 msec 소요

![Image](https://github.com/user-attachments/assets/ba730b91-ec8f-4ce4-9458-2e4731dc53b7)

> 예약, 계좌 상태 업데이트 : 3 msec 소요

![Image](https://github.com/user-attachments/assets/9b36092e-8176-412f-b4d2-979c081d0395)

**총합 약 17ms 소요**됩니다. 현재는 부담이 크지 않지만, 다음과 같은 상황에선 문제 발생할 수 있습니다.

- 동시 결제 요청 증가 시 DB 커넥션 병목
- 각 도메인 로직 복잡화 및 외부 시스템 호출 추가
- 장애 발생 시 롤백 범위가 너무 커짐

이는 단일 트랜잭션 내에 **너무 많은 도메인 행위가 응집**되어 있기 때문입니다.

### 2. 여러 도메인 간의 강한 결합
pay() 메서드의 흐름은 다음과 같이 여러 도메인을 직접 다룹니다.

- **User 도메인**: 사용자 유효성 검증, 계좌 정보 조회
- **Reservation 도메인**: 예약 상태 검증 및 갱신
- **Payment 도메인**: 결제 금액 계산 및 생성
- **Account 도메인**: 계좌 잔액 차감
- **Point 도메인**: 포인트 적립 및 이력 관리

Payment 도메인의 주 행위는 결제 금액을 계산하고 결제 상태를 관리하는 것까지 입니다. 그 이외는 비관심사에 해당되며 이는 Payment 도메인에 대한 응집도를 떨어뜨립니다.

### 3. 단일 실패지점 존재

현재 구조는 모든 로직이 **하나의 트랜잭션 내에서 실행**되기 때문에 단일 실패지점이 존재합니다.

- 중간 단계에서 하나라도 예외가 발생하면, **전체 결제 과정이 롤백**
- 예: 포인트 적립 실패 → 결제 정보도 롤백
- 일부는 이미 외부 시스템(예: 결제 게이트웨이, 계좌 차감 등)에 반영되었는데, 내부 DB만 롤백됨으로 인해 **데이터 불일치** 발행
- 도메인별 **장애 복구가 불가능**, 모든 작업을 재시도해야 함

# 개선 방안

## 1. 왜 이벤트 기반 아키텍처(EDA)가 필요한가?

현재 pay() 메서드는 하나의 트랜잭션 내에서 여러 도메인의 행위를 직접 수행하고 있습니다. 이는 강한 정합성을 보장하는 대신, 다음과 같은 단점을 야기합니다.

- **긴 트랜잭션 유지**: 성능 저하 및 DB 커넥션 고갈 우려
- **단일 실패 지점**: 한 도메인의 장애로 전체 결제 실패
- **결합도 증가**: 도메인 간 직접 참조로 유지보수 어려움

이러한 문제를 해결하기 위해 **도메인 간의 결합을 느슨하게 만들고**, 각 도메인이 독립적으로 행위를 처리하도록 하는 **이벤트 기반 아키텍처(Event-Driven Architecture, EDA)** 가 적합합니다.

> EDA의 핵심은 “하나의 도메인은 자신의 행위를 마친 후, 그 결과를 이벤트로 발행하고 끝낸다”는 점입니다. 이후의 후속 작업은 이벤트를 수신한 도메인에서 각자 책임지므로, 각 도메인은 독립성과 복원력을 확보할 수 있습니다.

### 2. 트랜잭셔널 아웃박스 패턴 적용
이벤트 기반으로 전환하는 과정에서, 데이터 일관성을 보장하기 위해 트랜잭셔널 아웃박스 패턴을 도입했습니다.

트랜잭셔널 아웃박스 패턴은 마이크로서비스 환경에서 데이터베이스 트랜잭션과 메시지 발행 간의 일관성을 보장하는 설계 방식입니다.

전반적인 흐름은 아래와 같습니다.
#### **흐름 정리**
1. **결제 요청** (pay() 호출)
    - Payment 엔티티 생성 (상태: PAYMENT_ATTEMPT)
    - PaymentAttemptEvent 발행 → Outbox 테이블에 저장

2. **Outbox Polling → Kafka 전송**
    - Outbox 테이블의 이벤트를 Kafka로 발행
    - Account 도메인이 PaymentAttemptEvent를 수신

3. **Account 도메인**
    - 중복 차감 방지 검증
    - 계좌 차감 성공 시 AccountDebitedEvent 발행
    - 실패 시 AccountDebitFailedEvent 발행

4. **Payment 도메인**
    - AccountDebitedEvent 수신 → Payment 상태 SUCCESS로 변경, PaymentSuccessEvent 발행
    - AccountDebitFailedEvent 수신 → Payment 상태 CANCELLED로 변경

5. **Point 도메인**
    - PaymentSuccessEvent 수신 → 포인트 적립 수행

도메인 이벤트는 `@TransactionalEventListener`의 phase를 `BEFORE_COMMIT`으로 둠으로써, 해당 트랜잭션이 커밋되기 이전에 발행되며 해당 트랜잭션의 성공 여부에 따라서 도메인 이벤트 발행 여부도 달라집니다. 이는 이벤트 발행이 누락되거나 이벤트만 발행되는 상황을 방지합니다.
아웃박스 패턴은 이벤트 발행 시, 이벤트 저장소(아웃박스)에 해당 이벤트를 기록함으로써 at-least-once(최소 한번 발행)을 보장하도록 합니다.
현재 구현 코드 내에서도 `EventStatus`를 `INIT`으로 초기 발행 상태의 이벤트를 이벤트 저장소에 기록합니다.
```java
@TransactionalEventListener( phase = TransactionPhase.BEFORE_COMMIT )  
public void saveEventOutBoxForPaymentAttempted( PaymentAttemptEvent paymentAttemptEvent ) {  
    eventOutboxService.save(  
            AggregateType.PAYMENT,  
            paymentAttemptEvent,  
            paymentAttemptEvent.getAggregateId(),  
            paymentAttemptEvent.getEventType(),  
            paymentAttemptEvent.createdAt(),  
            EventStatus.INIT  
    );  
}  

@Async
@TransactionalEventListener( phase = TransactionPhase.AFTER_COMMIT )  
public void sendPaymentAttemptEvent( PaymentAttemptEvent paymentAttemptEvent ) {  
    eventOutboxService.publishEvent( paymentAttemptEvent );  
}
```

토픽의 실질적인 발행은 외부 인프라인 kafka를 통해 발행합니다.
이를 위해  `@TransactionalEventListener( phase = TransactionPhase.AFTER_COMMIT )`를 사용하게 되면, 스프링 단에서 트랜잭션 커밋 이후에 해당 메서드를 실행할 것을 강하게 보장하기 때문에 kafka publisher의 토픽 발행을 보장할 수 있습니다.

만약 이 과정에서 토픽 발행에 성공한다면 “SEND_SUCCESS”, 실패한다면 해당 이벤트의 상태는 “SEND_FAILURE” 상태를 가집니다.

### **3. 이벤트 정의 및 구성 방식**
모든 이벤트는 AggregateEvent 인터페이스를 구현하며, 다음과 같은 공통 필드를 포함합니다:
```java
public interface AggregateEvent {
    Long getAggregateId(); // 해당 도메인의 식별자
    EventType getEventType(); // 예: PAYMENT_ATTEMPT, ACCOUNT_DEBIT_SUCCESS 등
    EventStatus getEventStatus(); // INIT, SEND_SUCCESS, SEND_FAILURE
    LocalDateTime getEventDate();
}
```

예시) 결제 시도 이벤트
```java
public record PaymentAttemptEvent(
        EventType eventType, 
        EventStatus eventStatus, 
        Long paymentId, 
        LocalDateTime createdAt,
        // payload
        Long userId, 
        Long reservationId, 
        BigDecimal totalPrice
) implements AggregateEvent { 
    public PaymentAttemptEvent(Long paymentId, Long userId, BigDecimal totalPrice, Long reservationId) {
        this(EventType.PAYMENT_ATTEMPT, EventStatus.INIT, paymentId, LocalDateTime.now(), userId, reservationId, totalPrice);
    }
}
```

위처럼 도메인 간 통신에 필요한 정보만 포함한 Payload 구조를 통해, 도메인 독립성을 유지하면서도 필요한 데이터를 전달합니다.

### 4. Propagation.REQUIRES_NEW를 통한 실패 시의 이벤트 처리
현재, 컨슈머 측은 다음과 같이 이벤트를 수신 중입니다.
```java
@KafkaListener( topics = "PAYMENT_ATTEMPT", groupId = "group_1" )  
public void handlePaymentAttemptEvent(  
        @Payload PaymentAttemptEvent event,  
        @Header("eventId") String eventId  
) {  
    processor.process( event, eventId );  
}
```
이때 프로세서라는 클래스로 해당 이벤트와 이벤트 아이디를 담아 전송하는 데, 이 프로세서는 다음과 같은 역할을 합니다.
- 컨슈머 측 도메인 행위 성공 시, 콜백 함수 정의
- 컨슈머 측 도메인 행위 실패 시, 콜백 함수 정의
- 실패 시 스킵 여부
  실제로 아래와 같이 직접 콜백함수를 DI해주는 방식으로 정의해주었습니다.
```java
@Transactional  
public void process( PaymentAttemptEvent event, String eventIdStr ) {  
    processor.process(  
            eventIdStr,  
            event,  
            ConsumerType.ACCOUNT_DEBIT,  
            e -> {  
                Long accountId = accountService.debit( e.userId(), e.totalPrice().longValue() );  
                eventPublisher.publish( new AccountDebitedEvent( accountId, e.userId(), e.reservationId() ) );  
            },  
            (e, ex) -> {  
                eventPublisher.publish( new AccountDebitFailedEvent( e.userId(), e.reservationId() ) );  
            },  
            true  
    );  
}
```

하지만 실패 이벤트에 대한 콜백을 처리하는 과정에서 실제로 콜백 함수가 호출되지 않아, 실패에 따른 도메인 이벤트 발행 및 실패 시 스킵에 대한 영속화 과정이 생략되는 문제가 발생했습니다.

문제의 원인은 이미 실행 중인 트랜잭션 내에서 실패에 따른 콜백 함수를 또 다른 트랜잭션으로 묶은 것 때문이었습니다.

스프링 트랜잭션은 기본적인 설정으로 트랜잭션 내의 트랜잭션 실행 시, 외부 트랜잭션의 범위로 내부 트랜잭션의 범위를 바꾸어 버립니다. 그래서 컨슈머 측 도메인 행위가 성공할 때는 상관없으나, 실패 할 때는 예외가 발생하게 되면서 내, 외부 트랜잭션 모두 롤백 되버리는 것입니다. 이로인해 실패 시 콜백함수는 실행되지 않고 끝나버립니다.

>@Transactional(propagation = Propagation.REQUIRES_NEW) 도입.

위와 같은 문제를 해결하기 위해 스프링의 기본 트랜잭션 옵션 대신, `Propagation.REQUIRES`를 사용하였습니다. 이 옵션은 이미 시작된 트랜잭션이 있다면 이를 보류하고 새로운 트랜잭션을 시작합니다. 이를 통해 기존에 실행 중이던 트랜잭션의 롤백에 영향을 받지 않고 실패 시 콜백을 성공적으로 수행할 수 있었습니다.

```java
@Transactional(propagation = Propagation.REQUIRES_NEW)  
public <T extends AggregateEvent> void handleFailure(  
        Long eventId,  
        T event,  
        ConsumerType consumerType,  
        Consumer<T> failureLogic,  
        boolean shouldSkip  
) {  
    if ( shouldSkip ) {  
        processedMessageRepository.save( ProcessedMessage.skip( eventId, consumerType ));  
    }  
    failureLogic.accept(event);  
}
```

> REQUIRES_NEW로 인한 데드락 문제.

결론적으로는 현재 구현 상에 있어 데드락 문제가 크게 없으나, 가능성 자체에 대해서는 없다고 확신할 수 없습니다. 우선, REQUIRES_NEW은 기존 트랜잭션이 있어도 일단 중단 시키고 완전히 새로운 트랜잭션을 시작합니다. 그리고 기존 트랜잭션은 새로운 트랜잭션이 종료될 때까지 대기 상태에 머무르게 됩니다. 만약 이러한 상태에서 두 트랜잭션이 같은 리소스를 잠그려고 한다면 트랜잭션 대기 현상이 발생하게 되며 결과적으로 데드락이 발생합니다.

이를 예방하기 위해 저는 외, 내부 트랜잭션이 접근할 수 있는 리소스의 타입을 확실히 정하기로 했습니다.
우선, 도메인 행위가 수행되는 외부 트랜잭션은 `RESERVATION` 테이블과 같이 실제 도메인 행위와 연관된 테이블에 접근합니다. 하지만, 내부 트랜잭션(실패 시 트랜잭션)은 실패 시 도메인 이벤트만 발행하고, `processed_message`와 같은 실패 처리 전용 테이블에만 접근하도록 합니다.


### 5. 실패 이벤트에 대한 재시도 전략

이벤트 기반 시스템에서는 Kafka 전송과정에서 실패할 수 있으므로, **실패 이벤트 재처리**가 중요합니다.
```java
@Scheduled(fixedRate = 60000)  
public void retryFailedEvents() {  
    logger.info("Retry Failed Outbox Event Scheduler Executed");  
    eventOutboxService.retryUnprocessedEvents();  
}
```

```java
@Transactional  
public void retryUnprocessedEvents() {  
    LocalDateTime threshold = LocalDateTime.now().minusMinutes(5);  
  
    List<OutboxMessage> unprocessed = eventOutboxRepository  
            .findAllByStatusNotAndBeforeDate(EventStatus.SEND_SUCCESS, threshold);  
  
    for (OutboxMessage message : unprocessed) {  
        AggregateEvent event = outboxEventMapper.toEventObject(  
                message.getPayload(),  
                message.getEventType()  
        );  
        publishEvent( event );  
    }  
}
```

프로듀서 측에서는 도메인 행위 자체가 완료된다면 BEFORE_COMMIT옵션을 통해 INIT 상태로 이벤트가 저장됩니다. 하지만, 브로커 측에서 오류가 발생하여 정상적으로 메세지를 송신할 수 없는 상황이라던가 아얘 어플리케이션이 다운 되면서 AFTER_COMMIT 옵션이 붙은 메서드를 실행조차 할 수 없는 상황이라면 INIT혹은 SEND_FAILURE 상태가 됩니다.

이 때문에 SEND_SUCCESS를 제외한 모든 이벤트를 아웃박스에서 가져옴으로써 재발행을 수행할 수 있게 됩니다.

### 6. 중복 이벤트 처리

이벤트 기반 구조에서는 시스템 간의 **비동기 메시지 전파**, **재시도**, **오류 복구** 등의 이유로 **동일 이벤트가 여러 번 수신될 수 있습니다.** 따라서 각 도메인의 컨슈머는 이벤트를 수신할 때 **중복 수신 여부를 확인하고, 이미 처리된 이벤트는 무시**해야 합니다.

#### 중복 이벤트 검증 방식

| **테이블**           | **역할**                                                                               |
| ----------------- | ------------------------------------------------------------------------------------ |
| message           | 발행할 메시지 정보를 저장 (Outbox 역할)                                                           |
| processed_message | 해당 메시지가 **성공적으로 발행되었거나**, **처리가 불가능하다고 판단되어 skip**된 경우 **기록** (idempotent 처리를 위한 기록) |

1. **복수 노드에서 동시 처리할 때 DB Lock 회피**
    - message 테이블을 직접 업데이트하거나 삭제하면 충돌이 발생할 수 있음 (특히 index scan + row-level lock 동시작업 시)
    - processed_message 테이블에 기록하는 방식은 단순 insert이므로 충돌 위험이 작고 성능상 유리

2. **중복 메시지 처리 방지 (Idempotent Consumer)**
    - 메시지가 Kafka로 여러 번 전송되더라도, 컨슈머는 processed_message에 기록된 message_id를 기준으로 중복 처리를 막을 수 있음

3. **문제가 된 메시지에 대한 트러블슈팅과 롤백 유연성**
    - message 테이블에는 원본 메시지 정보가 남고, processed_message에는 처리 여부만 저장됨 → 분석 및 재시도에 유리

중복 처리는 앞서 살펴본 `process` 메서드에서 진행합니다.
```java
...
if ( processedMessageRepository.existsById( new ProcessedMessageId( eventId, consumerType ) ) ) {  
    log.info( "[Kafka] Skip already processed eventId={}", eventId );  
    return;  
}
...
```
위와 같이 ProcessedMessage 테이블에서 특정 이벤트의 특정 컨슈머로 수신했는지의 여부를 복합키를 통해서 확인하고 있습니다.


### 7. 컨슈머 측 Retry 전략 및 DLT 구성

이벤트 기반 아키텍처에서는 네트워크 지연, 일시적인 오류, 외부 시스템 불안정 등으로 인해 Kafka 메시지 소비 중 예외가 발생할 수 있습니다. 이로 인해 일시적인 실패가 전체 도메인 행위를 방해하지 않도록, 컨슈머 측에는 재시도 및 DLT(Dead Letter Topic) 기반의 장애 대응 전략을 구성하였습니다.

#### 7.1 재시도 전략 구성
Spring Kafka의 CommonErrorHandler를 활용하여 다음과 같은 재시도 정책을 적용하였습니다.
- 메시지 처리 실패 시, 최대 3회까지 재시도합니다.
- 재시도 간격은 2초입니다.
- 3회 재시도에도 실패할 경우, DLT(Dead Letter Topic)로 메시지를 전송합니다
  재시도 설정 예시는 다음과 같습니다.
```java
@Bean
public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(KafkaTemplate<?, ?> kafkaTemplate) {
    ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory());
    factory.setCommonErrorHandler(errorHandler(kafkaTemplate));
    factory.setRecordMessageConverter(new StringJsonMessageConverter());
    return factory;
}

public CommonErrorHandler errorHandler(KafkaTemplate<?, ?> kafkaTemplate) {
    DeadLetterPublishingRecoverer recoverer = new DeadLetterPublishingRecoverer(
        kafkaTemplate,
        (record, ex) -> new TopicPartition(record.topic() + ".DLT", record.partition())
    );

    DefaultErrorHandler errorHandler = new DefaultErrorHandler(recoverer, new FixedBackOff(2000L, 3));

    errorHandler.setRetryListeners((record, ex, deliveryAttempt) -> {
        log.warn("Retrying (attempt {}): key={}, topic={}, error={}",
                deliveryAttempt, record.key(), record.topic(), ex.getMessage());
    });

    return errorHandler;
}
```

#### **7.2 컨슈머 측 멱등성 보장**

동일 메시지가 여러 번 수신될 수 있는 Kafka의 특성을 고려하여, 컨슈머는 ProcessedMessage 테이블을 조회하여 이미 처리된 메시지인지 여부를 확인합니다. 이로써 중복 메시지 처리로 인한 부작용을 방지합니다.

```java
if (processedMessageRepository.existsById(new ProcessedMessageId(eventId, consumerType))) {
    log.info("Skip already processed eventId={}, consumerType={}", eventId, consumerType);
    return;
}
```

이 구조는 재시도뿐 아니라 DLT로부터 재전송된 메시지에 대해서도 안정적으로 멱등성을 보장합니다.

### 8. 트랜잭셔널 아웃박스 패턴의 이점과 한계

트랜잭셔널 아웃박스 패턴은 마이크로서비스 환경에서 **데이터베이스 트랜잭션과 메시지 발행 간의 일관성을 보장하기 위해 사용되는 설계 방식**입니다. 본 프로젝트에서 이 패턴을 도입함으로써 다음과 같은 실질적인 이점을 얻을 수 있었습니다.

첫째, **도메인 간의 결합도**를 효과적으로 낮출 수 있습니다. 기존에는 하나의 트랜잭션 내에서 여러 도메인의 로직을 직접 호출해야 했지만, 아웃박스 패턴을 적용함으로써 각 도메인은 자신이 처리해야 할 행위만 수행하고 결과를 이벤트로 발행하도록 분리하였습니다. 이를 통해 각 도메인이 독립적으로 유지될 수 있는 기반이 마련되었습니다.

둘째, 장애 발생 시 전체 프로세스가 중단되는 일이 줄어들고, **장애를 국지적으로 격리**할 수 있게 되었습니다. 예를 들어, 계좌 차감 실패와 같은 도메인 오류가 발생하더라도, 이로 인해 결제 도메인의 로직 전체가 롤백되지 않고, 후속 도메인에서 적절한 이벤트 처리로 대응할 수 있게 되었습니다.

셋째, Outbox 테이블에 저장된 이벤트 정보를 기반으로 **Kafka 메시지를 재발행할 수 있는 구조**를 갖추게 되었습니다. 이로써 일시적인 네트워크 문제나 브로커 오류로 인해 메시지 전송이 실패하더라도, 이벤트를 다시 발행할 수 있어 데이터 손실 없이 안정적인 처리를 보장할 수 있습니다.

넷째, 멱등성 처리를 위한 **ProcessedMessage 테이블을 활용**함으로써, 동일한 메시지가 여러 번 전달되더라도 도메인 로직이 중복 실행되지 않도록 제어할 수 있게 되었습니다. 이는 재전송, 재시도 등 다양한 상황에서도 일관된 결과를 보장하는 데 기여합니다.

다섯째, 이벤트가 발행된 시점과 상태, 처리 여부 등의 정보를 데이터베이스에 기록함으로써 **전체 메시지 흐름을 추적하고 분석**할 수 있는 기반을 마련하였습니다. 이는 운영 환경에서의 트러블슈팅이나 장애 원인 분석에도 매우 유용합니다.

물론, 트랜잭셔널 아웃박스 패턴은 몇 가지 주의할 점과 제한 사항도 존재합니다.

첫 번째로, 메시지 전송을 주기적인 배치 스레드나 스케줄러를 통해 처리하는 구조에서는 실시간성이 다소 떨어질 수 있습니다. 특히 즉시 반응이 필요한 업무에 대해서는 약간의 지연이 발생할 수 있으므로, 필요에 따라 실시간 Outbox Processor 또는 Change Data Capture(CDC) 방식과 병행하는 방안도 고려해야 합니다.

두 번째로, 전체 시스템의 아키텍처가 복잡해집니다. Kafka, Outbox 테이블, DLT 구성, 멱등성 관리, 재시도 전략 등 다양한 인프라 컴포넌트가 추가되어 초기 설계와 운영 관리의 부담이 커질 수 있습니다.

세 번째로, 처리 흐름이 비동기로 분리되면서 **디버깅 및 트러블슈팅이 어려워질 수 있습니다.** 특히 이벤트 순서, 전파 타이밍, 메시지 중복 여부 등을 고려해야 하므로 로그와 모니터링 기반의 운영 전략이 함께 마련되어야 합니다.

네 번째로, 트랜잭션 관리 전략에 따라 **데드락이 발생할 가능성**도 존재합니다. 예를 들어, Propagation.REQUIRES_NEW와 같은 옵션을 사용할 경우, 외부 트랜잭션과 내부 트랜잭션 간의 리소스 잠금 충돌이 발생할 수 있습니다. 이를 방지하려면 트랜잭션 경계를 명확히 나누고, 동일 테이블에 대한 접근을 피하는 등의 설계적 고려가 필요합니다.

마지막으로, 재처리 기준에 대한 명확한 정의가 요구됩니다. 모든 이벤트가 동일한 컨슈머에게 전달되지 않기 때문에, 각 이벤트에 대해 어떤 컨슈머가 처리해야 하는지를 사전에 정의하고, 이를 기반으로 처리 여부를 판별하는 로직이 필요합니다.
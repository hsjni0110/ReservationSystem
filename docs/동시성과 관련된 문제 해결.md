
# 1. 개요
고속버스 예약 시스템은 다수의 사용자가 동시에 접속하고 요청을 보낼 수 있는 서비스입니다. 이런 환경에서는 **잔액 충전 요청의 중복 처리**, **좌석 예약 시 중복 예약**과 같은 문제가 발생할 수 있으며, 이는 곧 데이터 정합성과 서비스 신뢰도에 큰 영향을 미칩니다.

본 시스템에서는 이러한 문제를 해결하기 위해 **낙관적 락**, **비관적 락**, **Redis 기반의 분산 락**을 상황에 맞게 적용하여 **정합성과 성능을 모두 고려한 설계**를 구현하였습니다.

<br />

# 2. 문제 정의

<br />

## 잔액 충전 로직에서의 문제
- 유저가 잔액을 충전하는 요청이 네트워크 지연, 프론트의 중복 전송 등에 의해 **동시에 여러 번 호출**될 수 있습니다.
- 이 경우 **잔액은 단 한 번만 충전**되어야 하나, 동시성 제어가 없으면 **중복 충전이 발생**할 수 있습니다.

<br />

## 버스 예약 로직에서의 문제
- **동일한 좌석**을 여러 사용자가 동시에 예약하려 할 경우, **오직 한 명만이 예약에 성공**해야 합니다.
- 동시성 제어가 미비하면 **중복 예약**이 발생하여 시스템 무결성이 손상됩니다.

<br />

# 3. 동시성 제어 실패의 원인

- 트랜잭션 범위가 지나치게 넓어 **경합 시간 증가** 및 **데드락 발생** 가능성 존재합니다.
- 단위 기능에 맞춰 **트랜잭션 분리**가 이루어지지 않습니다.
- DB 연결이 길게 유지되어 전체 성능에 **악영향**을 미칩니다.

<br />

즉, 위와 같은 동시성 문제에 대응하기 위해서 트랜잭션의 범위를 좁히고 더 세밀하게 동시성을 제어할 필요가 있습니다.

<br />

## 4. 잔액 충전 로직 개선 : 낙관적 락 적용

낙관적 락은 데이터에 직접 락을 걸지 않고, 데이터가 수정되지 않았다고 ‘가정’하고 먼저 업데이트를 시도한 뒤, **버전 정보를 비교하여 충돌 여부를 판단**합니다.
- 충돌이 발생하지 않으면 그대로 저장
- 버전이 다르면 예외를 발생시키고, 필요시 재시도    
  낙관적 락은 **업데이트가 자주 발생하지 않는 데이터**에 적합하며, **트랜잭션 시간이 짧고 충돌 확률이 낮은 경우 성능상 유리**합니다.

<br />

### 적용방법
Account 엔티티에 @Version 어노테이션을 추가합니다.

<br />

```java
@Entity
public class Account {
    ...
    @Version
    private Long version; // 낙관적 락 버전 필드
}
```

<br />

그리고 충전 시에는 해당 버전을 기준으로 조회합니다.

```java
@Lock(LockModeType.OPTIMISTIC)
@Query("select a from Account a where a.user = :user")
Optional<Account> findByUserForUpdate(User user);
```

만약 버전이 일치하지 않는 경우 단순히 예외를 발생시키는 것으로 끝나는 것이 아니라 재조회를 한다던가 하려면 직접 구현해 주어야 합니다. 이 과정에서 비관적 락보다는 시간이 조금 길어질 수 있습니다.

<br />

```java  
@DisplayName("계좌 동시성 처리에서")  
@DisplayNameGeneration(DisplayNameGenerator.ReplaceUnderscores.class)  
@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)public class AccountConcurrencyTest {  
    @Autowired  
    private AccountService accountService;  
  
    @Autowired  
    private AccountRepository accountRepository;  
  
    @Autowired  
    private UserRepository userRepository;  
  
    private User user;  
  
    @BeforeEach  
    @Transactional    void setup() {  
        user = userRepository.save(유저());  
        accountRepository.save(  
                new Account(1L, user, Money.wons(100L))  
        );    
	}  
    @Test  
    void 동시에_여러_충전이_들어와도_한_번만_충전되어야_한다() throws InterruptedException {        // given        var threadCount = 10;        var executorService = Executors.newFixedThreadPool(threadCount);  
        var latch = new CountDownLatch(threadCount);
        var rechargeAmount = 100L;        
        var successfulRecharges = new AtomicLong(0);        
        var failedRecharges = new AtomicLong(0);  
        // when        for (int i = 0; i < threadCount; i++) {  
            executorService.submit(() -> {  
                try {                    
	                accountService.recharge(user.getUserId(), rechargeAmount);  
                    successfulRecharges.incrementAndGet();
				} catch (Exception e) {  
                    failedRecharges.incrementAndGet();                
				} finally { 
					latch.countDown();                
				}            
			});        
		}        
		latch.await();  
        executorService.shutdown();  
        executorService.awaitTermination(10, TimeUnit.SECONDS);  
  
        // then        assertEquals(1, successfulRecharges.get(), "오직 한 번만 충전에 성공해야 한다.");  
        assertEquals(9, failedRecharges.get(), "나머지는 모두 실패한다.");  
    }  
}  
```  

<br />

### 테스트 결과
- 10개 스레드 테스트: 단 1회 충전 성공 (정상)
- 100개 스레드 테스트: 최대 13회 충전 성공 (정합성 문제 발생)

<br />

<img width="865" alt="image" src="https://github.com/user-attachments/assets/075629f9-6cf7-4e5c-ac27-bed60a944d52">  

<br />

<img width="1156" alt="image" src="https://github.com/user-attachments/assets/9abebf75-6d2e-4f54-9d65-10817eeb268f">

<br />

### 개선 방향
낙관적 락은 성능 측면에서는 우수하지만, **충돌 발생 시 적절한 예외 처리 및 재시도 전략**을 수립하지 않으면 **데이터 중복**이 발생할 수 있습니다.

<br />

# 5. 좌석 예약 로직 개선: 비관적 락 + 트랜잭션 분리

비관적 락은 동시 업데이트가 빈번하게 일어날 것이라 '비관적'으로 가정하고 락을 거는 방식입니다.  
따라서 데이터를 읽는 시점에 락을 걸어 다른 트랜잭션의 접근을 차단합니다. 이는 데이터의 무결성을 강하게 보장하지만, 동시성 처리 속도가 느려질 수 있습니다.

<br />

### 적용 방식
ScheduledSeat를 조회할 때 **PESSIMISTIC_WRITE** 락을 사용하여 다른 트랜잭션에서 해당 좌석에 접근하지 못하도록 합니다.

<br />

```java
@Lock(LockModeType.PESSIMISTIC_WRITE)
@Query("select s from ScheduledSeat s where s.id = :id")
ScheduledSeat findByIdWithPessimisticLock(Long id);
```
조회된 좌석에 대해 이미 예약되었는지 확인하고, 예약되지 않았다면 예약 상태로 변경합니다.

<br />

```java  
@Transactional
public Reservation preserve(...) {
    List<ScheduledSeat> seats = scheduleSeatIds.stream()
        .map(scheduledSeatRepository::findByIdWithPessimisticLock)
        .toList();

    for (ScheduledSeat seat : seats) {
        if (seat.isReserved()) throw new ReservationException(...);
        seat.updateStatus(true);
    }

    return reservationRepository.save(...);
}
```  

<br />

### **테스트 결과**
- 1000개의 동시 요청 테스트에서도 **한 명만 성공**하여 좌석을 예약함 → 데이터 정합성 완벽 보장

<br />

```java  
@Test  
void 동시에_예약하면_하나만_성공해야_한다() throws InterruptedException {    
	// given    var threadCount = 1000;    var routeScheduleId = 1L;    var seatId = 1L;    var executorService = Executors.newFixedThreadPool(threadCount);  
    var countDownLatch = new CountDownLatch(threadCount);  
    AtomicInteger successCount = new AtomicInteger(0);  
    for (int i = 0; i < threadCount; i++) {  
        final long userId = i + 1;
        executorService.submit(() -> {  
            try {
	            userRepository.save(유저(userId));  
                reservationService.preserveSeat(userId, routeScheduleId, List.of(seatId));
                successCount.incrementAndGet();
			} catch (ReservationException e) {  
            } finally {
	            countDownLatch.countDown();
			}
		});
	}  
    countDownLatch.await();  
    executorService.shutdown();  
  
    assertThat(successCount.get()).isEqualTo(1);  
}  
```  

<br />

<img width="829" alt="image" src="https://github.com/user-attachments/assets/12310407-e5d7-4b6b-b266-439cb9f7b28c">  

<br />

## 분산 환경 대응: Redis 기반 분산 락 적용

<br />

### 적용 배경 및 필요성

<br />

고속버스 예약 시스템은 **멀티 인스턴스 환경** 또는 **클라우드 기반 마이크로서비스 구조**로 확장되기 때문에, 단순한 데이터베이스 수준의 락만으로는 인스턴스 간 동시성을 완벽하게 제어하기 어렵습니다.

예를 들어, 두 사용자가 서로 다른 서버 인스턴스를 통해 동일 좌석에 대해 예약 요청을 보낼 경우, 데이터베이스 트랜잭션이 시작되기 전까지는 충돌을 감지할 수 없습니다.

이를 해결하기 위해 **Redis 기반 분산 락**을 적용함으로써 **애플리케이션 레벨에서 자원 점유를 제어**하고, **데이터베이스에 도달하기 전에 충돌을 예방**하는 구조를 설계하였습니다.

<br />

### 구현 방식: 어노테이션 + AOP + RedisTemplate

<br />

#### 분산 락 선언 @DistributedSimpleLock

<br />

```java
@Target(ElementType.METHOD)
@Retention(RetentionPolicy.RUNTIME)
public @interface DistributedSimpleLock {
    String key();                     // 락 키
    long waitTime() default 5;        // 락 획득 대기 시간
    long releaseTime() default 10;    // 락 유지 시간
    TimeUnit timeUnit() default TimeUnit.SECONDS;
}
```
- **key**: 락의 고유 식별자 (예: 예약 노선 ID, 좌석 ID 등)
- **waitTime**: 락을 기다릴 최대 시간 (지정 시간 내 획득 실패 시 예외 발생)
- **releaseTime**: 락 점유 시간이 지나면 자동 만료되도록 설정

<br />

#### 락 적용 대상: AOP 기반 DistributedSimpleLockAspect

<br />

```java
@Around("@annotation(distributedSimpleLock)")
public Object around(...) {
    ...
    boolean acquired = redisSimpleLock.tryLock(...);
    if (!acquired) throw new BusinessException(OTHER_THREAD_ASSIGNED);
    try {
        return joinPoint.proceed();
    } finally {
        redisSimpleLock.releaseLock(...);
    }
}
```

<br />

- 락 획득 후 비즈니스 로직 수행
- 로직 종료와 동시에 락 해제

<br />

### 다좌석 예약 시 락 병렬 처리 + 데드락 해결

<br />

#### 여러 좌석 동시 예약 시 데드락 가능성

<br />

고속버스 예약은 보통 사용자가 **한 번에 여러 좌석을 선택**하여 동시에 예약하는 구조입니다. 예를 들어 아래와 같은 상황입니다.

<br />

```java
seatIds = [1, 3, 2]
```
이 경우 두 사용자가 **[1,2,3]**, **[3,2,1]** 순서로 락을 획득하려 하면 서로 **락 점유 순서가 꼬여 데드락**이 발생할 수 있습니다.
AOP를 활용하여 @DistributedSimpleLock이 붙은 메서드에 대해 **호출 전 Redis 락 획득**, **종료 시 락 해제**가 자동으로 수행됩니다.

<br />

#### 좌석 ID 정렬을 통한 락 순서 고정

<br />

```java
List<String> lockKeys = seatIds.stream()
    .map(id -> prefix + ":" + id)
    .sorted()
    .toList();
```
<br />

- 모든 요청에서 **항상 동일한 순서**로 락을 획득함으로써 데드락 방지
- 락 획득 도중 실패하면 **획득한 모든 락을 해제**하고 즉시 예외 반환

<br />

```java
for (String key : lockKeys) {
        boolean success = redisSimpleLock.tryLock(...);
        if (!success) {
             throw new BusinessException(OTHER_THREAD_ASSIGNED);
        }
        acquiredKeys.add(key);
}
```

<br />

### 6.4 RedisSimpleLock 구현

<br />

```java
public boolean tryLock(String key, String value, long leaseTime, TimeUnit timeUnit) {
    return redisTemplate.opsForValue()
        .setIfAbsent(key, value, leaseTime, timeUnit);
}

public boolean releaseLock(String key, String value) {
    String lockValue = redisTemplate.opsForValue().get(key);
    if (value.equals(lockValue)) {
        redisTemplate.delete(key);
        return true;
    }
    return false;
}
```

<br />

- **setIfAbsent** 명령어를 사용하여 Redis에 락을 등록
- value는 UUID로 설정하여 **본인 락만 해제**할 수 있도록 보호

<br />

### 적용 위치 분리

AOP는 **같은 클래스 내부의 메서드 호출 시 적용되지 않는** 구조적 한계가 있습니다. 이를 해결하기 위해 락 로직은 ReservationLockManager라는 별도의 클래스로 위임하였습니다.

<br />

```java
@Component
public class ReservationLockManager {
    @DistributedSimpleLock(
        key = "'reservation:' + #routeScheduleId + ':' + #scheduleSeatIds",
        waitTime = 1, releaseTime = 5
    )
    public Reservation preserveWithLock(Long userId, Long routeScheduleId, List<Long> scheduleSeatIds) {
        return reservationManager.preserve(userId, routeScheduleId, scheduleSeatIds);
    }
}
```

<br />

→ **비즈니스 로직은 ReservationManager에서 수행**, **락 획득은 Manager에서 책임 분리**

<br />

### **6.7 성능 개선 및 테스트 결과**

<br />

- **분산 락 미적용 시**: 동시성 문제 발생 가능성 높고, 실패 응답 불안정
- **분산 락 적용 후**: 충돌 전 차단 → 오류율 감소, 평균 응답시간 단축

실제로, 속도 면에서도 이점이 있는 지 확인해보겠습니다.
- 분산락 적용 이전  
  <img width="967" alt="image" src="https://github.com/user-attachments/assets/f70b2a2a-43af-4a89-83c8-4d9709729380">
- 분산락 적용 이후  
  <img width="1030" alt="image" src="https://github.com/user-attachments/assets/c91e920e-6550-420c-bf0c-be07966a1cc2">

<br />

## 분산 락 설계 평가

<br />

Redis 기반 분산 락은 단순한 락 이상의 역할을 합니다.
- **다중 좌석 락 병렬 처리** 시 데드락 방지를 위한 설계 적용
- 락 획득 실패 시 **예외 처리 및 자원 해제 설계**로 안정성 확보
- **멀티 인스턴스 환경**에서 발생할 수 있는 Race Condition 문제 해결

<br />

> 결과적으로 이 설계를 통해 **수천 명의 동시 접속 환경에서도 안정적인 버스 예약**이 가능해졌으며, 시스템 전체의 트랜잭션 정합성, 성능, 확장성까지 동시에 확보할 수 있게 되었습니다.